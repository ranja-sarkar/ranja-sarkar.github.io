
During my doctoral research, I had used the software Mathematica by Wolfram. My visits to the Wolfram Mathworld page gradually became rare events. 
I visited it recently and landed at their pages of [Probability & Statistics](https://mathworld.wolfram.com/topics/ProbabilityandStatistics.html). 
And I couldn't help exclaim, 'how beautifully demonstrated!‚Äù  
Maybe I was too distracted back then to have not noticed, or I was too much into partial differential equations (PDEs).

The French Mathematician, A. de Moivre developed 'normal distribution' as an approximation to [binomial distribution](https://mathworld.wolfram.com/BinomialDistribution.html). 

The [normal distribution](https://mathworld.wolfram.com/NormalDistribution.html) becomes a 'standard normal distribution' of a variate with zero mean & unity variance.  
 
The ratio of two standard normal variates gets us a [Cauchy](https://mathworld.wolfram.com/CauchyDistribution.html) variate.   

The square of a standard normal variate gets us a [Chi-squared](https://mathworld.wolfram.com/Chi-SquaredDistribution.html) variate.  

The addition/sum of Chi-squared variates gets us a [gamma](https://mathworld.wolfram.com/GammaDistribution.html) variate (another Chi-squared variate) and the ratio of two independent gamma variates gets us a beta variate.  
The beta distribution, for both shape parameters equal to unity that is, beta (1, 1) becomes a standard [uniform distribution](https://mathworld.wolfram.com/UniformDistribution.html).  

One can use [Box-Muller transformation](https://mathworld.wolfram.com/Box-MullerTransformation.html) on two independent standard uniform variates to arrive at two standard normal variates.  
 
I dug up the web deeper and found an [illustration](https://www.math.wm.edu/~leemis/chart/UDR/UDR.html) of the relationships between distributions.
