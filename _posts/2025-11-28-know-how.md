---
tags: [statistics, data]
---

Ranja Sarkar

-----

Let me start with an acronym iid; iid is independent & identically distributed which implies a collection of random variables where each variable has a probability distribution same as others in the collection and all of them are mutually independent. 

The **law of large numbers** states that when this collection is a large sample, the sample mean converges to the true mean if it exists. The law applies to the average obtained from a large number of repeated trials and claims that this average converges to the expected (or mean) value. 

he **central limit theorem (CLT)** states that, given a sufficiently large sample size, the sampling distribution of the mean for a random variable approximates a normal distribution regardless of itâ€™s distribution in the population. 

CLT is vital for two reasons, the normality assumption and the precision of estimates. The normality assumption is vital for parametric hypothesis tests of the mean. One might think that these tests are not valid when the data are non-normally distributed. However, if our sample size is large enough, CLT kicks in and produces sampling distributions that approximate a normal distribution. This fact allows us to use these hypothesis tests even when our data are non-normally distributed as long as the sample size is large enough.

The 'precision of estimates' property of CLT becomes relevant when we use a sample to estimate the mean of an entire population. With a larger sample size, the sample mean is more likely to be close to the real population mean. In other words, our estimate is precise.

Btw, descriptive statistics only helps draw inference about a sample. Inferential statistics helps draw inference about the population. If the sample is representive of the population, both stats yield same results.
